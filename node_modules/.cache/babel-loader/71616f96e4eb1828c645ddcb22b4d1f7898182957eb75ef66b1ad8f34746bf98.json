{"ast":null,"code":"'use strict';\n\nconst util = require('util');\nconst crypto = require('crypto');\nconst fs = require('fs');\nconst Minipass = require('minipass');\nconst path = require('path');\nconst ssri = require('ssri');\nconst uniqueFilename = require('unique-filename');\nconst {\n  disposer\n} = require('./util/disposer');\nconst contentPath = require('./content/path');\nconst fixOwner = require('./util/fix-owner');\nconst hashToSegments = require('./util/hash-to-segments');\nconst indexV = require('../package.json')['cache-version'].index;\nconst moveFile = require('@npmcli/move-file');\nconst _rimraf = require('rimraf');\nconst rimraf = util.promisify(_rimraf);\nrimraf.sync = _rimraf.sync;\nconst appendFile = util.promisify(fs.appendFile);\nconst readFile = util.promisify(fs.readFile);\nconst readdir = util.promisify(fs.readdir);\nconst writeFile = util.promisify(fs.writeFile);\nmodule.exports.NotFoundError = class NotFoundError extends Error {\n  constructor(cache, key) {\n    super(`No cache entry for ${key} found in ${cache}`);\n    this.code = 'ENOENT';\n    this.cache = cache;\n    this.key = key;\n  }\n};\nmodule.exports.compact = compact;\nasync function compact(cache, key, matchFn) {\n  let opts = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : {};\n  const bucket = bucketPath(cache, key);\n  const entries = await bucketEntries(bucket);\n  const newEntries = [];\n  // we loop backwards because the bottom-most result is the newest\n  // since we add new entries with appendFile\n  for (let i = entries.length - 1; i >= 0; --i) {\n    const entry = entries[i];\n    // a null integrity could mean either a delete was appended\n    // or the user has simply stored an index that does not map\n    // to any content. we determine if the user wants to keep the\n    // null integrity based on the validateEntry function passed in options.\n    // if the integrity is null and no validateEntry is provided, we break\n    // as we consider the null integrity to be a deletion of everything\n    // that came before it.\n    if (entry.integrity === null && !opts.validateEntry) break;\n\n    // if this entry is valid, and it is either the first entry or\n    // the newEntries array doesn't already include an entry that\n    // matches this one based on the provided matchFn, then we add\n    // it to the beginning of our list\n    if ((!opts.validateEntry || opts.validateEntry(entry) === true) && (newEntries.length === 0 || !newEntries.find(oldEntry => matchFn(oldEntry, entry)))) newEntries.unshift(entry);\n  }\n  const newIndex = '\\n' + newEntries.map(entry => {\n    const stringified = JSON.stringify(entry);\n    const hash = hashEntry(stringified);\n    return `${hash}\\t${stringified}`;\n  }).join('\\n');\n  const setup = async () => {\n    const target = uniqueFilename(path.join(cache, 'tmp'), opts.tmpPrefix);\n    await fixOwner.mkdirfix(cache, path.dirname(target));\n    return {\n      target,\n      moved: false\n    };\n  };\n  const teardown = async tmp => {\n    if (!tmp.moved) return rimraf(tmp.target);\n  };\n  const write = async tmp => {\n    await writeFile(tmp.target, newIndex, {\n      flag: 'wx'\n    });\n    await fixOwner.mkdirfix(cache, path.dirname(bucket));\n    // we use @npmcli/move-file directly here because we\n    // want to overwrite the existing file\n    await moveFile(tmp.target, bucket);\n    tmp.moved = true;\n    try {\n      await fixOwner.chownr(cache, bucket);\n    } catch (err) {\n      if (err.code !== 'ENOENT') throw err;\n    }\n  };\n\n  // write the file atomically\n  await disposer(setup(), teardown, write);\n\n  // we reverse the list we generated such that the newest\n  // entries come first in order to make looping through them easier\n  // the true passed to formatEntry tells it to keep null\n  // integrity values, if they made it this far it's because\n  // validateEntry returned true, and as such we should return it\n  return newEntries.reverse().map(entry => formatEntry(cache, entry, true));\n}\nmodule.exports.insert = insert;\nfunction insert(cache, key, integrity) {\n  let opts = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : {};\n  const {\n    metadata,\n    size\n  } = opts;\n  const bucket = bucketPath(cache, key);\n  const entry = {\n    key,\n    integrity: integrity && ssri.stringify(integrity),\n    time: Date.now(),\n    size,\n    metadata\n  };\n  return fixOwner.mkdirfix(cache, path.dirname(bucket)).then(() => {\n    const stringified = JSON.stringify(entry);\n    // NOTE - Cleverness ahoy!\n    //\n    // This works because it's tremendously unlikely for an entry to corrupt\n    // another while still preserving the string length of the JSON in\n    // question. So, we just slap the length in there and verify it on read.\n    //\n    // Thanks to @isaacs for the whiteboarding session that ended up with\n    // this.\n    return appendFile(bucket, `\\n${hashEntry(stringified)}\\t${stringified}`);\n  }).then(() => fixOwner.chownr(cache, bucket)).catch(err => {\n    if (err.code === 'ENOENT') return undefined;\n    throw err;\n    // There's a class of race conditions that happen when things get deleted\n    // during fixOwner, or between the two mkdirfix/chownr calls.\n    //\n    // It's perfectly fine to just not bother in those cases and lie\n    // that the index entry was written. Because it's a cache.\n  }).then(() => {\n    return formatEntry(cache, entry);\n  });\n}\nmodule.exports.insert.sync = insertSync;\nfunction insertSync(cache, key, integrity) {\n  let opts = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : {};\n  const {\n    metadata,\n    size\n  } = opts;\n  const bucket = bucketPath(cache, key);\n  const entry = {\n    key,\n    integrity: integrity && ssri.stringify(integrity),\n    time: Date.now(),\n    size,\n    metadata\n  };\n  fixOwner.mkdirfix.sync(cache, path.dirname(bucket));\n  const stringified = JSON.stringify(entry);\n  fs.appendFileSync(bucket, `\\n${hashEntry(stringified)}\\t${stringified}`);\n  try {\n    fixOwner.chownr.sync(cache, bucket);\n  } catch (err) {\n    if (err.code !== 'ENOENT') throw err;\n  }\n  return formatEntry(cache, entry);\n}\nmodule.exports.find = find;\nfunction find(cache, key) {\n  const bucket = bucketPath(cache, key);\n  return bucketEntries(bucket).then(entries => {\n    return entries.reduce((latest, next) => {\n      if (next && next.key === key) return formatEntry(cache, next);else return latest;\n    }, null);\n  }).catch(err => {\n    if (err.code === 'ENOENT') return null;else throw err;\n  });\n}\nmodule.exports.find.sync = findSync;\nfunction findSync(cache, key) {\n  const bucket = bucketPath(cache, key);\n  try {\n    return bucketEntriesSync(bucket).reduce((latest, next) => {\n      if (next && next.key === key) return formatEntry(cache, next);else return latest;\n    }, null);\n  } catch (err) {\n    if (err.code === 'ENOENT') return null;else throw err;\n  }\n}\nmodule.exports.delete = del;\nfunction del(cache, key) {\n  let opts = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : {};\n  if (!opts.removeFully) return insert(cache, key, null, opts);\n  const bucket = bucketPath(cache, key);\n  return rimraf(bucket);\n}\nmodule.exports.delete.sync = delSync;\nfunction delSync(cache, key) {\n  let opts = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : {};\n  if (!opts.removeFully) return insertSync(cache, key, null, opts);\n  const bucket = bucketPath(cache, key);\n  return rimraf.sync(bucket);\n}\nmodule.exports.lsStream = lsStream;\nfunction lsStream(cache) {\n  const indexDir = bucketDir(cache);\n  const stream = new Minipass({\n    objectMode: true\n  });\n  readdirOrEmpty(indexDir).then(buckets => Promise.all(buckets.map(bucket => {\n    const bucketPath = path.join(indexDir, bucket);\n    return readdirOrEmpty(bucketPath).then(subbuckets => Promise.all(subbuckets.map(subbucket => {\n      const subbucketPath = path.join(bucketPath, subbucket);\n\n      // \"/cachename/<bucket 0xFF>/<bucket 0xFF>./*\"\n      return readdirOrEmpty(subbucketPath).then(entries => Promise.all(entries.map(entry => {\n        const entryPath = path.join(subbucketPath, entry);\n        return bucketEntries(entryPath).then(entries =>\n        // using a Map here prevents duplicate keys from\n        // showing up twice, I guess?\n        entries.reduce((acc, entry) => {\n          acc.set(entry.key, entry);\n          return acc;\n        }, new Map())).then(reduced => {\n          // reduced is a map of key => entry\n          for (const entry of reduced.values()) {\n            const formatted = formatEntry(cache, entry);\n            if (formatted) stream.write(formatted);\n          }\n        }).catch(err => {\n          if (err.code === 'ENOENT') return undefined;\n          throw err;\n        });\n      })));\n    })));\n  }))).then(() => stream.end(), err => stream.emit('error', err));\n  return stream;\n}\nmodule.exports.ls = ls;\nfunction ls(cache) {\n  return lsStream(cache).collect().then(entries => entries.reduce((acc, xs) => {\n    acc[xs.key] = xs;\n    return acc;\n  }, {}));\n}\nmodule.exports.bucketEntries = bucketEntries;\nfunction bucketEntries(bucket, filter) {\n  return readFile(bucket, 'utf8').then(data => _bucketEntries(data, filter));\n}\nmodule.exports.bucketEntries.sync = bucketEntriesSync;\nfunction bucketEntriesSync(bucket, filter) {\n  const data = fs.readFileSync(bucket, 'utf8');\n  return _bucketEntries(data, filter);\n}\nfunction _bucketEntries(data, filter) {\n  const entries = [];\n  data.split('\\n').forEach(entry => {\n    if (!entry) return;\n    const pieces = entry.split('\\t');\n    if (!pieces[1] || hashEntry(pieces[1]) !== pieces[0]) {\n      // Hash is no good! Corruption or malice? Doesn't matter!\n      // EJECT EJECT\n      return;\n    }\n    let obj;\n    try {\n      obj = JSON.parse(pieces[1]);\n    } catch (e) {\n      // Entry is corrupted!\n      return;\n    }\n    if (obj) entries.push(obj);\n  });\n  return entries;\n}\nmodule.exports.bucketDir = bucketDir;\nfunction bucketDir(cache) {\n  return path.join(cache, `index-v${indexV}`);\n}\nmodule.exports.bucketPath = bucketPath;\nfunction bucketPath(cache, key) {\n  const hashed = hashKey(key);\n  return path.join.apply(path, [bucketDir(cache)].concat(hashToSegments(hashed)));\n}\nmodule.exports.hashKey = hashKey;\nfunction hashKey(key) {\n  return hash(key, 'sha256');\n}\nmodule.exports.hashEntry = hashEntry;\nfunction hashEntry(str) {\n  return hash(str, 'sha1');\n}\nfunction hash(str, digest) {\n  return crypto.createHash(digest).update(str).digest('hex');\n}\nfunction formatEntry(cache, entry, keepAll) {\n  // Treat null digests as deletions. They'll shadow any previous entries.\n  if (!entry.integrity && !keepAll) return null;\n  return {\n    key: entry.key,\n    integrity: entry.integrity,\n    path: entry.integrity ? contentPath(cache, entry.integrity) : undefined,\n    size: entry.size,\n    time: entry.time,\n    metadata: entry.metadata\n  };\n}\nfunction readdirOrEmpty(dir) {\n  return readdir(dir).catch(err => {\n    if (err.code === 'ENOENT' || err.code === 'ENOTDIR') return [];\n    throw err;\n  });\n}","map":{"version":3,"names":["util","require","crypto","fs","Minipass","path","ssri","uniqueFilename","disposer","contentPath","fixOwner","hashToSegments","indexV","index","moveFile","_rimraf","rimraf","promisify","sync","appendFile","readFile","readdir","writeFile","module","exports","NotFoundError","Error","constructor","cache","key","code","compact","matchFn","opts","arguments","length","undefined","bucket","bucketPath","entries","bucketEntries","newEntries","i","entry","integrity","validateEntry","find","oldEntry","unshift","newIndex","map","stringified","JSON","stringify","hash","hashEntry","join","setup","target","tmpPrefix","mkdirfix","dirname","moved","teardown","tmp","write","flag","chownr","err","reverse","formatEntry","insert","metadata","size","time","Date","now","then","catch","insertSync","appendFileSync","reduce","latest","next","findSync","bucketEntriesSync","delete","del","removeFully","delSync","lsStream","indexDir","bucketDir","stream","objectMode","readdirOrEmpty","buckets","Promise","all","subbuckets","subbucket","subbucketPath","entryPath","acc","set","Map","reduced","values","formatted","end","emit","ls","collect","xs","filter","data","_bucketEntries","readFileSync","split","forEach","pieces","obj","parse","e","push","hashed","hashKey","apply","concat","str","digest","createHash","update","keepAll","dir"],"sources":["/Users/user/node_modules/node-gyp/node_modules/cacache/lib/entry-index.js"],"sourcesContent":["'use strict'\n\nconst util = require('util')\nconst crypto = require('crypto')\nconst fs = require('fs')\nconst Minipass = require('minipass')\nconst path = require('path')\nconst ssri = require('ssri')\nconst uniqueFilename = require('unique-filename')\n\nconst { disposer } = require('./util/disposer')\nconst contentPath = require('./content/path')\nconst fixOwner = require('./util/fix-owner')\nconst hashToSegments = require('./util/hash-to-segments')\nconst indexV = require('../package.json')['cache-version'].index\nconst moveFile = require('@npmcli/move-file')\nconst _rimraf = require('rimraf')\nconst rimraf = util.promisify(_rimraf)\nrimraf.sync = _rimraf.sync\n\nconst appendFile = util.promisify(fs.appendFile)\nconst readFile = util.promisify(fs.readFile)\nconst readdir = util.promisify(fs.readdir)\nconst writeFile = util.promisify(fs.writeFile)\n\nmodule.exports.NotFoundError = class NotFoundError extends Error {\n  constructor (cache, key) {\n    super(`No cache entry for ${key} found in ${cache}`)\n    this.code = 'ENOENT'\n    this.cache = cache\n    this.key = key\n  }\n}\n\nmodule.exports.compact = compact\n\nasync function compact (cache, key, matchFn, opts = {}) {\n  const bucket = bucketPath(cache, key)\n  const entries = await bucketEntries(bucket)\n  const newEntries = []\n  // we loop backwards because the bottom-most result is the newest\n  // since we add new entries with appendFile\n  for (let i = entries.length - 1; i >= 0; --i) {\n    const entry = entries[i]\n    // a null integrity could mean either a delete was appended\n    // or the user has simply stored an index that does not map\n    // to any content. we determine if the user wants to keep the\n    // null integrity based on the validateEntry function passed in options.\n    // if the integrity is null and no validateEntry is provided, we break\n    // as we consider the null integrity to be a deletion of everything\n    // that came before it.\n    if (entry.integrity === null && !opts.validateEntry)\n      break\n\n    // if this entry is valid, and it is either the first entry or\n    // the newEntries array doesn't already include an entry that\n    // matches this one based on the provided matchFn, then we add\n    // it to the beginning of our list\n    if ((!opts.validateEntry || opts.validateEntry(entry) === true) &&\n      (newEntries.length === 0 ||\n        !newEntries.find((oldEntry) => matchFn(oldEntry, entry))))\n      newEntries.unshift(entry)\n  }\n\n  const newIndex = '\\n' + newEntries.map((entry) => {\n    const stringified = JSON.stringify(entry)\n    const hash = hashEntry(stringified)\n    return `${hash}\\t${stringified}`\n  }).join('\\n')\n\n  const setup = async () => {\n    const target = uniqueFilename(path.join(cache, 'tmp'), opts.tmpPrefix)\n    await fixOwner.mkdirfix(cache, path.dirname(target))\n    return {\n      target,\n      moved: false,\n    }\n  }\n\n  const teardown = async (tmp) => {\n    if (!tmp.moved)\n      return rimraf(tmp.target)\n  }\n\n  const write = async (tmp) => {\n    await writeFile(tmp.target, newIndex, { flag: 'wx' })\n    await fixOwner.mkdirfix(cache, path.dirname(bucket))\n    // we use @npmcli/move-file directly here because we\n    // want to overwrite the existing file\n    await moveFile(tmp.target, bucket)\n    tmp.moved = true\n    try {\n      await fixOwner.chownr(cache, bucket)\n    } catch (err) {\n      if (err.code !== 'ENOENT')\n        throw err\n    }\n  }\n\n  // write the file atomically\n  await disposer(setup(), teardown, write)\n\n  // we reverse the list we generated such that the newest\n  // entries come first in order to make looping through them easier\n  // the true passed to formatEntry tells it to keep null\n  // integrity values, if they made it this far it's because\n  // validateEntry returned true, and as such we should return it\n  return newEntries.reverse().map((entry) => formatEntry(cache, entry, true))\n}\n\nmodule.exports.insert = insert\n\nfunction insert (cache, key, integrity, opts = {}) {\n  const { metadata, size } = opts\n  const bucket = bucketPath(cache, key)\n  const entry = {\n    key,\n    integrity: integrity && ssri.stringify(integrity),\n    time: Date.now(),\n    size,\n    metadata,\n  }\n  return fixOwner\n    .mkdirfix(cache, path.dirname(bucket))\n    .then(() => {\n      const stringified = JSON.stringify(entry)\n      // NOTE - Cleverness ahoy!\n      //\n      // This works because it's tremendously unlikely for an entry to corrupt\n      // another while still preserving the string length of the JSON in\n      // question. So, we just slap the length in there and verify it on read.\n      //\n      // Thanks to @isaacs for the whiteboarding session that ended up with\n      // this.\n      return appendFile(bucket, `\\n${hashEntry(stringified)}\\t${stringified}`)\n    })\n    .then(() => fixOwner.chownr(cache, bucket))\n    .catch((err) => {\n      if (err.code === 'ENOENT')\n        return undefined\n\n      throw err\n      // There's a class of race conditions that happen when things get deleted\n      // during fixOwner, or between the two mkdirfix/chownr calls.\n      //\n      // It's perfectly fine to just not bother in those cases and lie\n      // that the index entry was written. Because it's a cache.\n    })\n    .then(() => {\n      return formatEntry(cache, entry)\n    })\n}\n\nmodule.exports.insert.sync = insertSync\n\nfunction insertSync (cache, key, integrity, opts = {}) {\n  const { metadata, size } = opts\n  const bucket = bucketPath(cache, key)\n  const entry = {\n    key,\n    integrity: integrity && ssri.stringify(integrity),\n    time: Date.now(),\n    size,\n    metadata,\n  }\n  fixOwner.mkdirfix.sync(cache, path.dirname(bucket))\n  const stringified = JSON.stringify(entry)\n  fs.appendFileSync(bucket, `\\n${hashEntry(stringified)}\\t${stringified}`)\n  try {\n    fixOwner.chownr.sync(cache, bucket)\n  } catch (err) {\n    if (err.code !== 'ENOENT')\n      throw err\n  }\n  return formatEntry(cache, entry)\n}\n\nmodule.exports.find = find\n\nfunction find (cache, key) {\n  const bucket = bucketPath(cache, key)\n  return bucketEntries(bucket)\n    .then((entries) => {\n      return entries.reduce((latest, next) => {\n        if (next && next.key === key)\n          return formatEntry(cache, next)\n        else\n          return latest\n      }, null)\n    })\n    .catch((err) => {\n      if (err.code === 'ENOENT')\n        return null\n      else\n        throw err\n    })\n}\n\nmodule.exports.find.sync = findSync\n\nfunction findSync (cache, key) {\n  const bucket = bucketPath(cache, key)\n  try {\n    return bucketEntriesSync(bucket).reduce((latest, next) => {\n      if (next && next.key === key)\n        return formatEntry(cache, next)\n      else\n        return latest\n    }, null)\n  } catch (err) {\n    if (err.code === 'ENOENT')\n      return null\n    else\n      throw err\n  }\n}\n\nmodule.exports.delete = del\n\nfunction del (cache, key, opts = {}) {\n  if (!opts.removeFully)\n    return insert(cache, key, null, opts)\n\n  const bucket = bucketPath(cache, key)\n  return rimraf(bucket)\n}\n\nmodule.exports.delete.sync = delSync\n\nfunction delSync (cache, key, opts = {}) {\n  if (!opts.removeFully)\n    return insertSync(cache, key, null, opts)\n\n  const bucket = bucketPath(cache, key)\n  return rimraf.sync(bucket)\n}\n\nmodule.exports.lsStream = lsStream\n\nfunction lsStream (cache) {\n  const indexDir = bucketDir(cache)\n  const stream = new Minipass({ objectMode: true })\n\n  readdirOrEmpty(indexDir).then(buckets => Promise.all(\n    buckets.map(bucket => {\n      const bucketPath = path.join(indexDir, bucket)\n      return readdirOrEmpty(bucketPath).then(subbuckets => Promise.all(\n        subbuckets.map(subbucket => {\n          const subbucketPath = path.join(bucketPath, subbucket)\n\n          // \"/cachename/<bucket 0xFF>/<bucket 0xFF>./*\"\n          return readdirOrEmpty(subbucketPath).then(entries => Promise.all(\n            entries.map(entry => {\n              const entryPath = path.join(subbucketPath, entry)\n              return bucketEntries(entryPath).then(entries =>\n                // using a Map here prevents duplicate keys from\n                // showing up twice, I guess?\n                entries.reduce((acc, entry) => {\n                  acc.set(entry.key, entry)\n                  return acc\n                }, new Map())\n              ).then(reduced => {\n                // reduced is a map of key => entry\n                for (const entry of reduced.values()) {\n                  const formatted = formatEntry(cache, entry)\n                  if (formatted)\n                    stream.write(formatted)\n                }\n              }).catch(err => {\n                if (err.code === 'ENOENT')\n                  return undefined\n                throw err\n              })\n            })\n          ))\n        })\n      ))\n    })\n  ))\n    .then(\n      () => stream.end(),\n      err => stream.emit('error', err)\n    )\n\n  return stream\n}\n\nmodule.exports.ls = ls\n\nfunction ls (cache) {\n  return lsStream(cache).collect().then(entries =>\n    entries.reduce((acc, xs) => {\n      acc[xs.key] = xs\n      return acc\n    }, {})\n  )\n}\n\nmodule.exports.bucketEntries = bucketEntries\n\nfunction bucketEntries (bucket, filter) {\n  return readFile(bucket, 'utf8').then((data) => _bucketEntries(data, filter))\n}\n\nmodule.exports.bucketEntries.sync = bucketEntriesSync\n\nfunction bucketEntriesSync (bucket, filter) {\n  const data = fs.readFileSync(bucket, 'utf8')\n  return _bucketEntries(data, filter)\n}\n\nfunction _bucketEntries (data, filter) {\n  const entries = []\n  data.split('\\n').forEach((entry) => {\n    if (!entry)\n      return\n\n    const pieces = entry.split('\\t')\n    if (!pieces[1] || hashEntry(pieces[1]) !== pieces[0]) {\n      // Hash is no good! Corruption or malice? Doesn't matter!\n      // EJECT EJECT\n      return\n    }\n    let obj\n    try {\n      obj = JSON.parse(pieces[1])\n    } catch (e) {\n      // Entry is corrupted!\n      return\n    }\n    if (obj)\n      entries.push(obj)\n  })\n  return entries\n}\n\nmodule.exports.bucketDir = bucketDir\n\nfunction bucketDir (cache) {\n  return path.join(cache, `index-v${indexV}`)\n}\n\nmodule.exports.bucketPath = bucketPath\n\nfunction bucketPath (cache, key) {\n  const hashed = hashKey(key)\n  return path.join.apply(\n    path,\n    [bucketDir(cache)].concat(hashToSegments(hashed))\n  )\n}\n\nmodule.exports.hashKey = hashKey\n\nfunction hashKey (key) {\n  return hash(key, 'sha256')\n}\n\nmodule.exports.hashEntry = hashEntry\n\nfunction hashEntry (str) {\n  return hash(str, 'sha1')\n}\n\nfunction hash (str, digest) {\n  return crypto\n    .createHash(digest)\n    .update(str)\n    .digest('hex')\n}\n\nfunction formatEntry (cache, entry, keepAll) {\n  // Treat null digests as deletions. They'll shadow any previous entries.\n  if (!entry.integrity && !keepAll)\n    return null\n\n  return {\n    key: entry.key,\n    integrity: entry.integrity,\n    path: entry.integrity ? contentPath(cache, entry.integrity) : undefined,\n    size: entry.size,\n    time: entry.time,\n    metadata: entry.metadata,\n  }\n}\n\nfunction readdirOrEmpty (dir) {\n  return readdir(dir).catch((err) => {\n    if (err.code === 'ENOENT' || err.code === 'ENOTDIR')\n      return []\n\n    throw err\n  })\n}\n"],"mappings":"AAAA,YAAY;;AAEZ,MAAMA,IAAI,GAAGC,OAAO,CAAC,MAAM,CAAC;AAC5B,MAAMC,MAAM,GAAGD,OAAO,CAAC,QAAQ,CAAC;AAChC,MAAME,EAAE,GAAGF,OAAO,CAAC,IAAI,CAAC;AACxB,MAAMG,QAAQ,GAAGH,OAAO,CAAC,UAAU,CAAC;AACpC,MAAMI,IAAI,GAAGJ,OAAO,CAAC,MAAM,CAAC;AAC5B,MAAMK,IAAI,GAAGL,OAAO,CAAC,MAAM,CAAC;AAC5B,MAAMM,cAAc,GAAGN,OAAO,CAAC,iBAAiB,CAAC;AAEjD,MAAM;EAAEO;AAAS,CAAC,GAAGP,OAAO,CAAC,iBAAiB,CAAC;AAC/C,MAAMQ,WAAW,GAAGR,OAAO,CAAC,gBAAgB,CAAC;AAC7C,MAAMS,QAAQ,GAAGT,OAAO,CAAC,kBAAkB,CAAC;AAC5C,MAAMU,cAAc,GAAGV,OAAO,CAAC,yBAAyB,CAAC;AACzD,MAAMW,MAAM,GAAGX,OAAO,CAAC,iBAAiB,CAAC,CAAC,eAAe,CAAC,CAACY,KAAK;AAChE,MAAMC,QAAQ,GAAGb,OAAO,CAAC,mBAAmB,CAAC;AAC7C,MAAMc,OAAO,GAAGd,OAAO,CAAC,QAAQ,CAAC;AACjC,MAAMe,MAAM,GAAGhB,IAAI,CAACiB,SAAS,CAACF,OAAO,CAAC;AACtCC,MAAM,CAACE,IAAI,GAAGH,OAAO,CAACG,IAAI;AAE1B,MAAMC,UAAU,GAAGnB,IAAI,CAACiB,SAAS,CAACd,EAAE,CAACgB,UAAU,CAAC;AAChD,MAAMC,QAAQ,GAAGpB,IAAI,CAACiB,SAAS,CAACd,EAAE,CAACiB,QAAQ,CAAC;AAC5C,MAAMC,OAAO,GAAGrB,IAAI,CAACiB,SAAS,CAACd,EAAE,CAACkB,OAAO,CAAC;AAC1C,MAAMC,SAAS,GAAGtB,IAAI,CAACiB,SAAS,CAACd,EAAE,CAACmB,SAAS,CAAC;AAE9CC,MAAM,CAACC,OAAO,CAACC,aAAa,GAAG,MAAMA,aAAa,SAASC,KAAK,CAAC;EAC/DC,WAAWA,CAAEC,KAAK,EAAEC,GAAG,EAAE;IACvB,KAAK,CAAE,sBAAqBA,GAAI,aAAYD,KAAM,EAAC,CAAC;IACpD,IAAI,CAACE,IAAI,GAAG,QAAQ;IACpB,IAAI,CAACF,KAAK,GAAGA,KAAK;IAClB,IAAI,CAACC,GAAG,GAAGA,GAAG;EAChB;AACF,CAAC;AAEDN,MAAM,CAACC,OAAO,CAACO,OAAO,GAAGA,OAAO;AAEhC,eAAeA,OAAOA,CAAEH,KAAK,EAAEC,GAAG,EAAEG,OAAO,EAAa;EAAA,IAAXC,IAAI,GAAAC,SAAA,CAAAC,MAAA,QAAAD,SAAA,QAAAE,SAAA,GAAAF,SAAA,MAAG,CAAC,CAAC;EACpD,MAAMG,MAAM,GAAGC,UAAU,CAACV,KAAK,EAAEC,GAAG,CAAC;EACrC,MAAMU,OAAO,GAAG,MAAMC,aAAa,CAACH,MAAM,CAAC;EAC3C,MAAMI,UAAU,GAAG,EAAE;EACrB;EACA;EACA,KAAK,IAAIC,CAAC,GAAGH,OAAO,CAACJ,MAAM,GAAG,CAAC,EAAEO,CAAC,IAAI,CAAC,EAAE,EAAEA,CAAC,EAAE;IAC5C,MAAMC,KAAK,GAAGJ,OAAO,CAACG,CAAC,CAAC;IACxB;IACA;IACA;IACA;IACA;IACA;IACA;IACA,IAAIC,KAAK,CAACC,SAAS,KAAK,IAAI,IAAI,CAACX,IAAI,CAACY,aAAa,EACjD;;IAEF;IACA;IACA;IACA;IACA,IAAI,CAAC,CAACZ,IAAI,CAACY,aAAa,IAAIZ,IAAI,CAACY,aAAa,CAACF,KAAK,CAAC,KAAK,IAAI,MAC3DF,UAAU,CAACN,MAAM,KAAK,CAAC,IACtB,CAACM,UAAU,CAACK,IAAI,CAAEC,QAAQ,IAAKf,OAAO,CAACe,QAAQ,EAAEJ,KAAK,CAAC,CAAC,CAAC,EAC3DF,UAAU,CAACO,OAAO,CAACL,KAAK,CAAC;EAC7B;EAEA,MAAMM,QAAQ,GAAG,IAAI,GAAGR,UAAU,CAACS,GAAG,CAAEP,KAAK,IAAK;IAChD,MAAMQ,WAAW,GAAGC,IAAI,CAACC,SAAS,CAACV,KAAK,CAAC;IACzC,MAAMW,IAAI,GAAGC,SAAS,CAACJ,WAAW,CAAC;IACnC,OAAQ,GAAEG,IAAK,KAAIH,WAAY,EAAC;EAClC,CAAC,CAAC,CAACK,IAAI,CAAC,IAAI,CAAC;EAEb,MAAMC,KAAK,GAAG,MAAAA,CAAA,KAAY;IACxB,MAAMC,MAAM,GAAGnD,cAAc,CAACF,IAAI,CAACmD,IAAI,CAAC5B,KAAK,EAAE,KAAK,CAAC,EAAEK,IAAI,CAAC0B,SAAS,CAAC;IACtE,MAAMjD,QAAQ,CAACkD,QAAQ,CAAChC,KAAK,EAAEvB,IAAI,CAACwD,OAAO,CAACH,MAAM,CAAC,CAAC;IACpD,OAAO;MACLA,MAAM;MACNI,KAAK,EAAE;IACT,CAAC;EACH,CAAC;EAED,MAAMC,QAAQ,GAAG,MAAOC,GAAG,IAAK;IAC9B,IAAI,CAACA,GAAG,CAACF,KAAK,EACZ,OAAO9C,MAAM,CAACgD,GAAG,CAACN,MAAM,CAAC;EAC7B,CAAC;EAED,MAAMO,KAAK,GAAG,MAAOD,GAAG,IAAK;IAC3B,MAAM1C,SAAS,CAAC0C,GAAG,CAACN,MAAM,EAAET,QAAQ,EAAE;MAAEiB,IAAI,EAAE;IAAK,CAAC,CAAC;IACrD,MAAMxD,QAAQ,CAACkD,QAAQ,CAAChC,KAAK,EAAEvB,IAAI,CAACwD,OAAO,CAACxB,MAAM,CAAC,CAAC;IACpD;IACA;IACA,MAAMvB,QAAQ,CAACkD,GAAG,CAACN,MAAM,EAAErB,MAAM,CAAC;IAClC2B,GAAG,CAACF,KAAK,GAAG,IAAI;IAChB,IAAI;MACF,MAAMpD,QAAQ,CAACyD,MAAM,CAACvC,KAAK,EAAES,MAAM,CAAC;IACtC,CAAC,CAAC,OAAO+B,GAAG,EAAE;MACZ,IAAIA,GAAG,CAACtC,IAAI,KAAK,QAAQ,EACvB,MAAMsC,GAAG;IACb;EACF,CAAC;;EAED;EACA,MAAM5D,QAAQ,CAACiD,KAAK,EAAE,EAAEM,QAAQ,EAAEE,KAAK,CAAC;;EAExC;EACA;EACA;EACA;EACA;EACA,OAAOxB,UAAU,CAAC4B,OAAO,EAAE,CAACnB,GAAG,CAAEP,KAAK,IAAK2B,WAAW,CAAC1C,KAAK,EAAEe,KAAK,EAAE,IAAI,CAAC,CAAC;AAC7E;AAEApB,MAAM,CAACC,OAAO,CAAC+C,MAAM,GAAGA,MAAM;AAE9B,SAASA,MAAMA,CAAE3C,KAAK,EAAEC,GAAG,EAAEe,SAAS,EAAa;EAAA,IAAXX,IAAI,GAAAC,SAAA,CAAAC,MAAA,QAAAD,SAAA,QAAAE,SAAA,GAAAF,SAAA,MAAG,CAAC,CAAC;EAC/C,MAAM;IAAEsC,QAAQ;IAAEC;EAAK,CAAC,GAAGxC,IAAI;EAC/B,MAAMI,MAAM,GAAGC,UAAU,CAACV,KAAK,EAAEC,GAAG,CAAC;EACrC,MAAMc,KAAK,GAAG;IACZd,GAAG;IACHe,SAAS,EAAEA,SAAS,IAAItC,IAAI,CAAC+C,SAAS,CAACT,SAAS,CAAC;IACjD8B,IAAI,EAAEC,IAAI,CAACC,GAAG,EAAE;IAChBH,IAAI;IACJD;EACF,CAAC;EACD,OAAO9D,QAAQ,CACZkD,QAAQ,CAAChC,KAAK,EAAEvB,IAAI,CAACwD,OAAO,CAACxB,MAAM,CAAC,CAAC,CACrCwC,IAAI,CAAC,MAAM;IACV,MAAM1B,WAAW,GAAGC,IAAI,CAACC,SAAS,CAACV,KAAK,CAAC;IACzC;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA,OAAOxB,UAAU,CAACkB,MAAM,EAAG,KAAIkB,SAAS,CAACJ,WAAW,CAAE,KAAIA,WAAY,EAAC,CAAC;EAC1E,CAAC,CAAC,CACD0B,IAAI,CAAC,MAAMnE,QAAQ,CAACyD,MAAM,CAACvC,KAAK,EAAES,MAAM,CAAC,CAAC,CAC1CyC,KAAK,CAAEV,GAAG,IAAK;IACd,IAAIA,GAAG,CAACtC,IAAI,KAAK,QAAQ,EACvB,OAAOM,SAAS;IAElB,MAAMgC,GAAG;IACT;IACA;IACA;IACA;IACA;EACF,CAAC,CAAC,CACDS,IAAI,CAAC,MAAM;IACV,OAAOP,WAAW,CAAC1C,KAAK,EAAEe,KAAK,CAAC;EAClC,CAAC,CAAC;AACN;AAEApB,MAAM,CAACC,OAAO,CAAC+C,MAAM,CAACrD,IAAI,GAAG6D,UAAU;AAEvC,SAASA,UAAUA,CAAEnD,KAAK,EAAEC,GAAG,EAAEe,SAAS,EAAa;EAAA,IAAXX,IAAI,GAAAC,SAAA,CAAAC,MAAA,QAAAD,SAAA,QAAAE,SAAA,GAAAF,SAAA,MAAG,CAAC,CAAC;EACnD,MAAM;IAAEsC,QAAQ;IAAEC;EAAK,CAAC,GAAGxC,IAAI;EAC/B,MAAMI,MAAM,GAAGC,UAAU,CAACV,KAAK,EAAEC,GAAG,CAAC;EACrC,MAAMc,KAAK,GAAG;IACZd,GAAG;IACHe,SAAS,EAAEA,SAAS,IAAItC,IAAI,CAAC+C,SAAS,CAACT,SAAS,CAAC;IACjD8B,IAAI,EAAEC,IAAI,CAACC,GAAG,EAAE;IAChBH,IAAI;IACJD;EACF,CAAC;EACD9D,QAAQ,CAACkD,QAAQ,CAAC1C,IAAI,CAACU,KAAK,EAAEvB,IAAI,CAACwD,OAAO,CAACxB,MAAM,CAAC,CAAC;EACnD,MAAMc,WAAW,GAAGC,IAAI,CAACC,SAAS,CAACV,KAAK,CAAC;EACzCxC,EAAE,CAAC6E,cAAc,CAAC3C,MAAM,EAAG,KAAIkB,SAAS,CAACJ,WAAW,CAAE,KAAIA,WAAY,EAAC,CAAC;EACxE,IAAI;IACFzC,QAAQ,CAACyD,MAAM,CAACjD,IAAI,CAACU,KAAK,EAAES,MAAM,CAAC;EACrC,CAAC,CAAC,OAAO+B,GAAG,EAAE;IACZ,IAAIA,GAAG,CAACtC,IAAI,KAAK,QAAQ,EACvB,MAAMsC,GAAG;EACb;EACA,OAAOE,WAAW,CAAC1C,KAAK,EAAEe,KAAK,CAAC;AAClC;AAEApB,MAAM,CAACC,OAAO,CAACsB,IAAI,GAAGA,IAAI;AAE1B,SAASA,IAAIA,CAAElB,KAAK,EAAEC,GAAG,EAAE;EACzB,MAAMQ,MAAM,GAAGC,UAAU,CAACV,KAAK,EAAEC,GAAG,CAAC;EACrC,OAAOW,aAAa,CAACH,MAAM,CAAC,CACzBwC,IAAI,CAAEtC,OAAO,IAAK;IACjB,OAAOA,OAAO,CAAC0C,MAAM,CAAC,CAACC,MAAM,EAAEC,IAAI,KAAK;MACtC,IAAIA,IAAI,IAAIA,IAAI,CAACtD,GAAG,KAAKA,GAAG,EAC1B,OAAOyC,WAAW,CAAC1C,KAAK,EAAEuD,IAAI,CAAC,MAE/B,OAAOD,MAAM;IACjB,CAAC,EAAE,IAAI,CAAC;EACV,CAAC,CAAC,CACDJ,KAAK,CAAEV,GAAG,IAAK;IACd,IAAIA,GAAG,CAACtC,IAAI,KAAK,QAAQ,EACvB,OAAO,IAAI,MAEX,MAAMsC,GAAG;EACb,CAAC,CAAC;AACN;AAEA7C,MAAM,CAACC,OAAO,CAACsB,IAAI,CAAC5B,IAAI,GAAGkE,QAAQ;AAEnC,SAASA,QAAQA,CAAExD,KAAK,EAAEC,GAAG,EAAE;EAC7B,MAAMQ,MAAM,GAAGC,UAAU,CAACV,KAAK,EAAEC,GAAG,CAAC;EACrC,IAAI;IACF,OAAOwD,iBAAiB,CAAChD,MAAM,CAAC,CAAC4C,MAAM,CAAC,CAACC,MAAM,EAAEC,IAAI,KAAK;MACxD,IAAIA,IAAI,IAAIA,IAAI,CAACtD,GAAG,KAAKA,GAAG,EAC1B,OAAOyC,WAAW,CAAC1C,KAAK,EAAEuD,IAAI,CAAC,MAE/B,OAAOD,MAAM;IACjB,CAAC,EAAE,IAAI,CAAC;EACV,CAAC,CAAC,OAAOd,GAAG,EAAE;IACZ,IAAIA,GAAG,CAACtC,IAAI,KAAK,QAAQ,EACvB,OAAO,IAAI,MAEX,MAAMsC,GAAG;EACb;AACF;AAEA7C,MAAM,CAACC,OAAO,CAAC8D,MAAM,GAAGC,GAAG;AAE3B,SAASA,GAAGA,CAAE3D,KAAK,EAAEC,GAAG,EAAa;EAAA,IAAXI,IAAI,GAAAC,SAAA,CAAAC,MAAA,QAAAD,SAAA,QAAAE,SAAA,GAAAF,SAAA,MAAG,CAAC,CAAC;EACjC,IAAI,CAACD,IAAI,CAACuD,WAAW,EACnB,OAAOjB,MAAM,CAAC3C,KAAK,EAAEC,GAAG,EAAE,IAAI,EAAEI,IAAI,CAAC;EAEvC,MAAMI,MAAM,GAAGC,UAAU,CAACV,KAAK,EAAEC,GAAG,CAAC;EACrC,OAAOb,MAAM,CAACqB,MAAM,CAAC;AACvB;AAEAd,MAAM,CAACC,OAAO,CAAC8D,MAAM,CAACpE,IAAI,GAAGuE,OAAO;AAEpC,SAASA,OAAOA,CAAE7D,KAAK,EAAEC,GAAG,EAAa;EAAA,IAAXI,IAAI,GAAAC,SAAA,CAAAC,MAAA,QAAAD,SAAA,QAAAE,SAAA,GAAAF,SAAA,MAAG,CAAC,CAAC;EACrC,IAAI,CAACD,IAAI,CAACuD,WAAW,EACnB,OAAOT,UAAU,CAACnD,KAAK,EAAEC,GAAG,EAAE,IAAI,EAAEI,IAAI,CAAC;EAE3C,MAAMI,MAAM,GAAGC,UAAU,CAACV,KAAK,EAAEC,GAAG,CAAC;EACrC,OAAOb,MAAM,CAACE,IAAI,CAACmB,MAAM,CAAC;AAC5B;AAEAd,MAAM,CAACC,OAAO,CAACkE,QAAQ,GAAGA,QAAQ;AAElC,SAASA,QAAQA,CAAE9D,KAAK,EAAE;EACxB,MAAM+D,QAAQ,GAAGC,SAAS,CAAChE,KAAK,CAAC;EACjC,MAAMiE,MAAM,GAAG,IAAIzF,QAAQ,CAAC;IAAE0F,UAAU,EAAE;EAAK,CAAC,CAAC;EAEjDC,cAAc,CAACJ,QAAQ,CAAC,CAACd,IAAI,CAACmB,OAAO,IAAIC,OAAO,CAACC,GAAG,CAClDF,OAAO,CAAC9C,GAAG,CAACb,MAAM,IAAI;IACpB,MAAMC,UAAU,GAAGjC,IAAI,CAACmD,IAAI,CAACmC,QAAQ,EAAEtD,MAAM,CAAC;IAC9C,OAAO0D,cAAc,CAACzD,UAAU,CAAC,CAACuC,IAAI,CAACsB,UAAU,IAAIF,OAAO,CAACC,GAAG,CAC9DC,UAAU,CAACjD,GAAG,CAACkD,SAAS,IAAI;MAC1B,MAAMC,aAAa,GAAGhG,IAAI,CAACmD,IAAI,CAAClB,UAAU,EAAE8D,SAAS,CAAC;;MAEtD;MACA,OAAOL,cAAc,CAACM,aAAa,CAAC,CAACxB,IAAI,CAACtC,OAAO,IAAI0D,OAAO,CAACC,GAAG,CAC9D3D,OAAO,CAACW,GAAG,CAACP,KAAK,IAAI;QACnB,MAAM2D,SAAS,GAAGjG,IAAI,CAACmD,IAAI,CAAC6C,aAAa,EAAE1D,KAAK,CAAC;QACjD,OAAOH,aAAa,CAAC8D,SAAS,CAAC,CAACzB,IAAI,CAACtC,OAAO;QAC1C;QACA;QACAA,OAAO,CAAC0C,MAAM,CAAC,CAACsB,GAAG,EAAE5D,KAAK,KAAK;UAC7B4D,GAAG,CAACC,GAAG,CAAC7D,KAAK,CAACd,GAAG,EAAEc,KAAK,CAAC;UACzB,OAAO4D,GAAG;QACZ,CAAC,EAAE,IAAIE,GAAG,EAAE,CAAC,CACd,CAAC5B,IAAI,CAAC6B,OAAO,IAAI;UAChB;UACA,KAAK,MAAM/D,KAAK,IAAI+D,OAAO,CAACC,MAAM,EAAE,EAAE;YACpC,MAAMC,SAAS,GAAGtC,WAAW,CAAC1C,KAAK,EAAEe,KAAK,CAAC;YAC3C,IAAIiE,SAAS,EACXf,MAAM,CAAC5B,KAAK,CAAC2C,SAAS,CAAC;UAC3B;QACF,CAAC,CAAC,CAAC9B,KAAK,CAACV,GAAG,IAAI;UACd,IAAIA,GAAG,CAACtC,IAAI,KAAK,QAAQ,EACvB,OAAOM,SAAS;UAClB,MAAMgC,GAAG;QACX,CAAC,CAAC;MACJ,CAAC,CAAC,CACH,CAAC;IACJ,CAAC,CAAC,CACH,CAAC;EACJ,CAAC,CAAC,CACH,CAAC,CACCS,IAAI,CACH,MAAMgB,MAAM,CAACgB,GAAG,EAAE,EAClBzC,GAAG,IAAIyB,MAAM,CAACiB,IAAI,CAAC,OAAO,EAAE1C,GAAG,CAAC,CACjC;EAEH,OAAOyB,MAAM;AACf;AAEAtE,MAAM,CAACC,OAAO,CAACuF,EAAE,GAAGA,EAAE;AAEtB,SAASA,EAAEA,CAAEnF,KAAK,EAAE;EAClB,OAAO8D,QAAQ,CAAC9D,KAAK,CAAC,CAACoF,OAAO,EAAE,CAACnC,IAAI,CAACtC,OAAO,IAC3CA,OAAO,CAAC0C,MAAM,CAAC,CAACsB,GAAG,EAAEU,EAAE,KAAK;IAC1BV,GAAG,CAACU,EAAE,CAACpF,GAAG,CAAC,GAAGoF,EAAE;IAChB,OAAOV,GAAG;EACZ,CAAC,EAAE,CAAC,CAAC,CAAC,CACP;AACH;AAEAhF,MAAM,CAACC,OAAO,CAACgB,aAAa,GAAGA,aAAa;AAE5C,SAASA,aAAaA,CAAEH,MAAM,EAAE6E,MAAM,EAAE;EACtC,OAAO9F,QAAQ,CAACiB,MAAM,EAAE,MAAM,CAAC,CAACwC,IAAI,CAAEsC,IAAI,IAAKC,cAAc,CAACD,IAAI,EAAED,MAAM,CAAC,CAAC;AAC9E;AAEA3F,MAAM,CAACC,OAAO,CAACgB,aAAa,CAACtB,IAAI,GAAGmE,iBAAiB;AAErD,SAASA,iBAAiBA,CAAEhD,MAAM,EAAE6E,MAAM,EAAE;EAC1C,MAAMC,IAAI,GAAGhH,EAAE,CAACkH,YAAY,CAAChF,MAAM,EAAE,MAAM,CAAC;EAC5C,OAAO+E,cAAc,CAACD,IAAI,EAAED,MAAM,CAAC;AACrC;AAEA,SAASE,cAAcA,CAAED,IAAI,EAAED,MAAM,EAAE;EACrC,MAAM3E,OAAO,GAAG,EAAE;EAClB4E,IAAI,CAACG,KAAK,CAAC,IAAI,CAAC,CAACC,OAAO,CAAE5E,KAAK,IAAK;IAClC,IAAI,CAACA,KAAK,EACR;IAEF,MAAM6E,MAAM,GAAG7E,KAAK,CAAC2E,KAAK,CAAC,IAAI,CAAC;IAChC,IAAI,CAACE,MAAM,CAAC,CAAC,CAAC,IAAIjE,SAAS,CAACiE,MAAM,CAAC,CAAC,CAAC,CAAC,KAAKA,MAAM,CAAC,CAAC,CAAC,EAAE;MACpD;MACA;MACA;IACF;IACA,IAAIC,GAAG;IACP,IAAI;MACFA,GAAG,GAAGrE,IAAI,CAACsE,KAAK,CAACF,MAAM,CAAC,CAAC,CAAC,CAAC;IAC7B,CAAC,CAAC,OAAOG,CAAC,EAAE;MACV;MACA;IACF;IACA,IAAIF,GAAG,EACLlF,OAAO,CAACqF,IAAI,CAACH,GAAG,CAAC;EACrB,CAAC,CAAC;EACF,OAAOlF,OAAO;AAChB;AAEAhB,MAAM,CAACC,OAAO,CAACoE,SAAS,GAAGA,SAAS;AAEpC,SAASA,SAASA,CAAEhE,KAAK,EAAE;EACzB,OAAOvB,IAAI,CAACmD,IAAI,CAAC5B,KAAK,EAAG,UAAShB,MAAO,EAAC,CAAC;AAC7C;AAEAW,MAAM,CAACC,OAAO,CAACc,UAAU,GAAGA,UAAU;AAEtC,SAASA,UAAUA,CAAEV,KAAK,EAAEC,GAAG,EAAE;EAC/B,MAAMgG,MAAM,GAAGC,OAAO,CAACjG,GAAG,CAAC;EAC3B,OAAOxB,IAAI,CAACmD,IAAI,CAACuE,KAAK,CACpB1H,IAAI,EACJ,CAACuF,SAAS,CAAChE,KAAK,CAAC,CAAC,CAACoG,MAAM,CAACrH,cAAc,CAACkH,MAAM,CAAC,CAAC,CAClD;AACH;AAEAtG,MAAM,CAACC,OAAO,CAACsG,OAAO,GAAGA,OAAO;AAEhC,SAASA,OAAOA,CAAEjG,GAAG,EAAE;EACrB,OAAOyB,IAAI,CAACzB,GAAG,EAAE,QAAQ,CAAC;AAC5B;AAEAN,MAAM,CAACC,OAAO,CAAC+B,SAAS,GAAGA,SAAS;AAEpC,SAASA,SAASA,CAAE0E,GAAG,EAAE;EACvB,OAAO3E,IAAI,CAAC2E,GAAG,EAAE,MAAM,CAAC;AAC1B;AAEA,SAAS3E,IAAIA,CAAE2E,GAAG,EAAEC,MAAM,EAAE;EAC1B,OAAOhI,MAAM,CACViI,UAAU,CAACD,MAAM,CAAC,CAClBE,MAAM,CAACH,GAAG,CAAC,CACXC,MAAM,CAAC,KAAK,CAAC;AAClB;AAEA,SAAS5D,WAAWA,CAAE1C,KAAK,EAAEe,KAAK,EAAE0F,OAAO,EAAE;EAC3C;EACA,IAAI,CAAC1F,KAAK,CAACC,SAAS,IAAI,CAACyF,OAAO,EAC9B,OAAO,IAAI;EAEb,OAAO;IACLxG,GAAG,EAAEc,KAAK,CAACd,GAAG;IACde,SAAS,EAAED,KAAK,CAACC,SAAS;IAC1BvC,IAAI,EAAEsC,KAAK,CAACC,SAAS,GAAGnC,WAAW,CAACmB,KAAK,EAAEe,KAAK,CAACC,SAAS,CAAC,GAAGR,SAAS;IACvEqC,IAAI,EAAE9B,KAAK,CAAC8B,IAAI;IAChBC,IAAI,EAAE/B,KAAK,CAAC+B,IAAI;IAChBF,QAAQ,EAAE7B,KAAK,CAAC6B;EAClB,CAAC;AACH;AAEA,SAASuB,cAAcA,CAAEuC,GAAG,EAAE;EAC5B,OAAOjH,OAAO,CAACiH,GAAG,CAAC,CAACxD,KAAK,CAAEV,GAAG,IAAK;IACjC,IAAIA,GAAG,CAACtC,IAAI,KAAK,QAAQ,IAAIsC,GAAG,CAACtC,IAAI,KAAK,SAAS,EACjD,OAAO,EAAE;IAEX,MAAMsC,GAAG;EACX,CAAC,CAAC;AACJ"},"metadata":{},"sourceType":"script","externalDependencies":[]}